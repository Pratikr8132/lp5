{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqTgKUSLhBeY",
        "outputId": "83367445-cc50-4085-e553-7ee8befd141c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRkqk__RhYr0",
        "outputId": "44dd2f38-d1ea-49b4-be22-803e727a56f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-7zfj3m_r\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-7zfj3m_r\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 5741c522547756ac4bb7a16df32106a15efb8a57\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvcc4jupyter\n",
            "  Building wheel for nvcc4jupyter (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvcc4jupyter: filename=nvcc4jupyter-1.2.1-py3-none-any.whl size=10741 sha256=1c43b610d84440f376c57bb0b3d20f87e2433fdb6f06eb98d5fd7c81c461a971\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-reqik072/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built nvcc4jupyter\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzBmFKOrhZq2",
        "outputId": "af8d6e44-0814-427d-a380-3c20f5120b6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmp2lf35mr4\".\n"
          ]
        }
      ],
      "source": [
        "%load_ext nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvPquimph6HH",
        "outputId": "5033aea5-0f26-47fe-8268-8c59a1d7ddb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------\n",
            "__SUCCESS__\n",
            "---------------------------\n",
            "N                 = 1048576\n",
            "Threads Per Block = 256\n",
            "Blocks In Grid    = 4096\n",
            "---------------------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cuda\n",
        "\n",
        "#include <iostream>\n",
        "\n",
        "// Size of array\n",
        "#define N 1048576\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "// Kernel\n",
        "__global__ void add_vectors(double *a, double *b, double *c)\n",
        "{\n",
        "    int id = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if(id < N) c[id] = a[id] + b[id];\n",
        "}\n",
        "\n",
        "// Main program\n",
        "int main()\n",
        "{\n",
        "    // Number of bytes to allocate for N doubles\n",
        "    size_t bytes = N*sizeof(double);\n",
        "\n",
        "    // Allocate memory for arrays A, B, and C on host\n",
        "    double *A = new double[N];\n",
        "    double *B = new double[N];\n",
        "    double *C = new double[N];\n",
        "\n",
        "    // Allocate memory for arrays d_A, d_B, and d_C on device\n",
        "    double *d_A, *d_B, *d_C;\n",
        "    cudaMalloc(&d_A, bytes);\n",
        "    cudaMalloc(&d_B, bytes);\n",
        "    cudaMalloc(&d_C, bytes);\n",
        "\n",
        "    // Fill host arrays A and B\n",
        "    for(int i=0; i<N; i++)\n",
        "    {\n",
        "        A[i] = 1.0;\n",
        "        B[i] = 2.0;\n",
        "    }\n",
        "\n",
        "    // Copy data from host arrays A and B to device arrays d_A and d_B\n",
        "    cudaMemcpy(d_A, A, bytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, B, bytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Set execution configuration parameters\n",
        "    //      thr_per_blk: number of CUDA threads per grid block\n",
        "    //      blk_in_grid: number of blocks in grid\n",
        "    int thr_per_blk = 256;\n",
        "    int blk_in_grid = ceil( float(N) / thr_per_blk );\n",
        "\n",
        "    // Launch kernel\n",
        "    add_vectors<<< blk_in_grid, thr_per_blk >>>(d_A, d_B, d_C);\n",
        "\n",
        "    // Copy data from device array d_C to host array C\n",
        "    cudaMemcpy(C, d_C, bytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Verify results\n",
        "    double tolerance = 1.0e-14;\n",
        "    for(int i=0; i<N; i++)\n",
        "    {\n",
        "        if( abs(C[i] - 3.0) > tolerance)\n",
        "        {\n",
        "            cout << \"Error: value of C[\" << i << \"] = \" << C[i] << \" instead of 3.0\" << endl;\n",
        "            exit(1);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Free memory\n",
        "    delete[] A;\n",
        "    delete[] B;\n",
        "    delete[] C;\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    cout << \"---------------------------\" << endl;\n",
        "    cout << \"__SUCCESS__\" << endl;\n",
        "    cout << \"---------------------------\" << endl;\n",
        "    cout << \"N                 = \" << N << endl;\n",
        "    cout << \"Threads Per Block = \" << thr_per_blk << endl;\n",
        "    cout << \"Blocks In Grid    = \" << blk_in_grid << endl;\n",
        "    cout << \"---------------------------\" << endl << endl;\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ic8mvKJukiQu",
        "outputId": "07128634-11c0-4fa7-8380-6eb104bb06cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44608256 111586048 178563840 245541632 312519424 379497216 446475008 513452800 580430592 647408384 \n",
            "111586048 312781568 513977088 715172608 916368128 1117563648 1318759168 1519954688 1721150208 1922345728 \n",
            "178563840 513977088 849390336 1184803584 1520216832 1855630080 -2103923968 -1768510720 -1433097472 -1097684224 \n",
            "245541632 715172608 1184803584 1654434560 2124065536 -1701270784 -1231639808 -762008832 -292377856 177253120 \n",
            "312519424 916368128 1520216832 2124065536 -1567053056 -963204352 -359355648 244493056 848341760 1452190464 \n",
            "379497216 1117563648 1855630080 -1701270784 -963204352 -225137920 512928512 1250994944 1989061376 -1567839488 \n",
            "446475008 1318759168 -2103923968 -1231639808 -359355648 512928512 1385212672 -2037470464 -1165186304 -292902144 \n",
            "513452800 1519954688 -1768510720 -762008832 244493056 1250994944 -2037470464 -1030968576 -24466688 982035200 \n",
            "580430592 1721150208 -1433097472 -292377856 848341760 1989061376 -1165186304 -24466688 1116252928 -2037994752 \n",
            "647408384 1922345728 -1097684224 177253120 1452190464 -1567839488 -292902144 982035200 -2037994752 -763057408 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cuda\n",
        "\n",
        "#include <iostream>\n",
        "void matmul(int *A, int *B, int *C, int N)\n",
        "{\n",
        "    for (int Row = 0; Row < N; Row++)\n",
        "    {\n",
        "        for (int Col = 0; Col < N; Col++)\n",
        "        {\n",
        "            int Pvalue = 0;\n",
        "            for (int k = 0; k < N; k++)\n",
        "            {\n",
        "                Pvalue += A[Row * N + k] * B[k * N + Col];\n",
        "            }\n",
        "            C[Row * N + Col] = Pvalue;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int N = 512;\n",
        "    int size = N * N * sizeof(int);\n",
        "    int *A, *B, *C;\n",
        "    A = new int[size];\n",
        "    B = new int[size];\n",
        "    C = new int[size];\n",
        "\n",
        "    for (int i = 0; i < N; i++)\n",
        "    {\n",
        "        for (int j = 0; j < N; j++)\n",
        "        {\n",
        "            A[i * N + j] = i * N + j;\n",
        "            B[i * N + j] = j * N + i;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    matmul(A, B, C, N);\n",
        "\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        for (int j = 0; j < 10; j++)\n",
        "        {\n",
        "            std::cout << C[i * N + j] << \" \";\n",
        "        }\n",
        "        std::cout << std::endl;\n",
        "    }\n",
        "\n",
        "    delete[] A;\n",
        "    delete[] B;\n",
        "    delete[] C;\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Certainly! Let's break down the provided code line by line:\n",
        "\n",
        "# cpp\n",
        "# Copy code\n",
        "# #include <iostream>\n",
        "# This line includes the iostream header file, which allows input and output operations, such as printing to the console.\n",
        "\n",
        "# cpp\n",
        "# Copy code\n",
        "# // Size of array\n",
        "# #define N 1048576\n",
        "# This line defines a constant N with a value of 1048576, representing the size of arrays used in the code.\n",
        "\n",
        "# cpp\n",
        "# Copy code\n",
        "# using namespace std;\n",
        "# This line declares that names from the standard C++ library (like cout and endl) will be used without explicitly specifying their namespace.\n",
        "\n",
        "# cpp\n",
        "# Copy code\n",
        "# // Kernel\n",
        "# __global__ void add_vectors(double *a, double *b, double *c)\n",
        "# This line defines a CUDA kernel function named add_vectors. Kernels are functions that are executed on the GPU. This particular kernel is meant to add two arrays a and b element-wise and store the result in array c.\n",
        "\n",
        "# cpp\n",
        "# Copy code\n",
        "# {\n",
        "#     int id = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "#     if(id < N) c[id] = a[id] + b[id];\n",
        "# }\n",
        "# Within the kernel function, this block of code calculates the unique index (id) of each thread based on its block and thread indices. It then checks if this index is within the range of the array size N, and if so, it performs the addition of corresponding elements from arrays a and b, storing the result in array c.\n",
        "\n",
        "# cpp\n",
        "# Copy code\n",
        "# // Main program\n",
        "# int main()\n",
        "# This line declares the main function of the program.\n",
        "\n",
        "# cpp\n",
        "# Copy code\n",
        "# {\n",
        "#     // Number of bytes to allocate for N doubles\n",
        "#     size_t bytes = N*sizeof(double);\n",
        "# This line calculates the total number of bytes needed to store N double precision floating-point numbers.\n",
        "\n",
        "# cpp\n",
        "# Copy code\n",
        "#     // Allocate memory for arrays A, B, and C on host\n",
        "#     double *A = new double[N];\n",
        "#     double *B = new double[N];\n",
        "#     double *C = new double[N];\n",
        "# This line dynamically allocates memory on the host (CPU) for three arrays A, B, and C, each containing N double precision floating-point numbers.\n",
        "\n",
        "# cpp\n",
        "# Copy code\n",
        "#     // Allocate memory for arrays d_A, d_B, and d_C on device\n",
        "#     double *d_A, *d_B, *d_C;\n",
        "#     cudaMalloc(&d_A, bytes);\n",
        "#     cudaMalloc(&d_B, bytes);\n",
        "#     cudaMalloc(&d_C, bytes);\n",
        "# These lines allocate memory on the device (GPU) for three arrays d_A, d_B, and d_C to store the input and output data for the CUDA kernel. cudaMalloc is a CUDA function used to allocate memory on the GPU.\n",
        "\n",
        "# cpp\n",
        "# Copy code\n",
        "#     // Fill host arrays A and B\n",
        "#     for(int i=0; i<N; i++)\n",
        "#     {\n",
        "#         A[i] = 1.0;\n",
        "#         B[i] = 2.0;\n",
        "#     }\n",
        "# This loop fills the host arrays A and B with the values 1.0 and 2.0, respectively.\n",
        "\n",
        "# cpp\n",
        "# Copy code\n",
        "#     // Copy data from host arrays A and B to device arrays d_A and d_B\n",
        "#     cudaMemcpy(d_A, A, bytes, cudaMemcpyHostToDevice);\n",
        "#     cudaMemcpy(d_B, B, bytes, cudaMemcpyHostToDevice);\n",
        "# These lines copy the data from the host arrays A and B to the corresponding device arrays d_A and d_B using cudaMemcpy. This function is used to transfer data between the CPU and GPU.\n",
        "\n",
        "# The code continues similarly, executing a CUDA kernel (add_vectors), copying the result back to the host (C), verifying the result, freeing memory, and printing some information about the execution configuration.\n",
        "\n",
        "# The second part of the code implements a matrix multiplication (matmul) function in C++. It multiplies two matrices A and B to produce a result matrix C. The matrices are filled with values and then multiplied using nested loops. Finally, the result matrix C is printed to the console."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
